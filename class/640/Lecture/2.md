**CS 640 Lecture 2: 01/19/2017**

A.  Addressing, Routing

B.  Packet Switching

C.  Statistical Multiplexing

D.  Layers and protocols

Recall from the last lecture, we have three fundamental requirements to
design our computer network:

-   Scalable Connectivity: Internet grows in the number of machines it connects every day. How do we connect them all?

-   Cost-efficient resource use:  When multiple sets of machines want  communicate over the Internet, how do we ensure sharing of network  resources (e.g., network capacity)? Key is to ensure they share in  a manner that the network is used *efficiently.* E.g., having each  pair of machines go at once, followed by another pair,  is inefficient.

-   Support for common services:  Many applications may need the same set  of mechanisms to enable their communication. This requirement is  about extracting out the common requirements and making them  available for many applications to use.

\#B, \#C above capture the second requirement. \#D above captures the
third requirement.

**A. Addressing, Routing**

-   “Address” - Provide a way for hosts to identify, reach each other.  They are end point identifiers used to label a host/ host's  network interface.

-   IP address :  Identifies end-point and encodes *network  location*. e.g. the IP address 128.2.3.6 labels a node or host in  a network numbered 128.2.

-   Layer 2 address (MAC address):  Identifies node or host alone; does  not carry any information about the network the host is  located in. Given by vendors. e.g. an Ethernet address  AE:00:23:45:67:89

-   Network routers use IP addresses for sending and forwarding (routing) messages.

-   Switches use MAC addresses for forwarding.

-   The process of determining how to forward messages along a sequence of switches or routers is called *routing*.

-   The outcome of routing is a set of tables in each switch or router that collectively determine the path of a message through a network.

-   When an endpoint's location changes, IP could change but MAC stays fixed.

**B. Packet Switching**

-   Circuit switching was used earlier. The steps involved were the following

    -   Signaling to network for establishing connection.

    -   Establishing a circuit (and optionally) reserving resources.

    -   Send/Stream data.

-   Disadvantages of circuit switching

    -   Signaling overhead (between nodes) adds time (latency)

    -   Reserving resources wastes bandwidth

-   Packet switching

    -   Nodes send each message as a sequence of discrete blocks of data.

    -   Each block is called a “packet”

    -   Network elements (Switches and routers): “store and forward packets”.

    -   Packets carry information (addresses) about who is sending them, and where they need to go.

    -   Switches receive each packet then decide where to send based on addresses

-   Advantages of packet switching

    -   No setup time, no prerequisite resources.

    -   More efficient.

-   Disadvantages of packet switching

    -   No b/w or performance guarantee

-   Circuit switching making a comeback with help of optical networks which provides higher bandwidth. These are used in data centers which require intense bandwidth (initial setup is not an issues in data centers).

**C. Statistical Multiplexing**

-   Central to cost effective networks.

-   Problem: Many applications want to use the network. How to “multiplex” or schedule them?

-   Candidates:

    -   TDM (Time division multiplexing): give time slots to each application. App sends packets in its time slot. Apps get time slots in a round-robin order, where round robin revisits an application every N slots.

    -   FDM (Frequency division multiplexing): give capacity (1/N of total capacity) to each application. App sends as many packets per unit time as the capacity allocated to it allows.

-   Problems with previous two:  is that bandwidth is wasted when  applications don't use it (slots assigned to them is wasted).  Also, we need to know how many senders are trying to send  simultaneously, i.e., the value of N above. This is hard to know  ahead of time, and might change as new applications, with their  messages, enter/leave.

-   **Statistical Multiplexing** -  like TDM data is sent by one  application at a time; i.e., first app1’s packet, then app2’s  packet etc. But data is transmitted *on demand* unlike TDM.

-   Just one app? App gets entire capacity  gets to send all its  packets back to back -- if it has enough such packets. When a new  app arrives, its packets start to get interleaved with the packets  of the first app.

-   Two things make statistical multiplexing work: MTU and FIFO

    -   To limit how much an application hogs the bandwidth, divide message into packets of size MTU or “Maximum Transmission Unit”

        -   Note: Hosts use “Path MTU Discovery” service to find the MTU.

    -   Switches use a buffer that implements FIFO first-in-first-out scheduling to enqueue/dequeue packets from apps. Packets from all the hosts are queued at the buffer. FIFO naturally implements apps’ sharing capacity.

-   Congestion – happens when the FIFO queues overflow. (drain rate of buffer < load from hosts) -> packets are dropped

- Internet: "best effort"

-   Putting it all together -- In a packet-switched network:

    -   Applications run on a network.

    -   Send messages into the network and the messages are switched hop-by-hop (packet switched).

    -   Messages are broken into packets.

    -   Packets are scheduled using statistical multiplexing.

    -   Packets arriving at a switch are buffered and sent out, typically in FIFO order

    -   When hosts send too fast, buffer at a switch can overflows -- this is called congestion

    -   Packets are dropped under congestion.

Note: Switches work w/in switch network, routers router switch networks

**D. Layers and protocols**

**We covered the following quickly toward the end of the lecture. We
revisited in more detail in lecture 3.**

-   Need: Make it easy to write applications that can use the network.  Hide complexity, abstract low level details.

-   Approach:

    -   Identify common requirements. e.g. reliability, time sensitive etc.

    -   Encapsulate into protocol.

-   e.g. Common application requirements are

      1. Reliable, in-order delay

      2. Timely delivery (reliability not necessary)

-   Leads to transport layer, containing 2 protocols

    -   1 uses TCP (Transmission Control Protocol)

    -   2 uses UDP (User Datagram Protocol)

-   No matter what the application's requirements are, they need basic  connectivity between end points. This is captured by the IP layer  and the IP protocol

-   Note: SCTP is Stream Control Transmission Protocol. It is  message oriented. It records boundaries, is reliable but  not in-order.

-   “Below” IP - hardware layers. A variety of protocols that may run in  individual switched networks.

-   IP – ties them together, enables inter-operation and provides a  unified interface to transport protocols.

-   *Protocols offer 2 interfaces*

    -   *Service interface: Defines the operations that local objects can perform on protocol e.g. HTTP's GET and POST. Service model tells what can the higher layer expect.*

    -   *Peer interface: Defines how the other end interprets a message e.g. format of GET.*
