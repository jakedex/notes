# Lecture 6 Notes (_9.21.16_)

### Memory ish

#### Translation Steps

1. extract VPN from VA
2. calculate addr of PTE (vpn * sizeof(pte) + ptbr)
3. read PTE from memory
4. extract PFN (page frame num)
5. build PA
6. read contents of PA from memory to register

### Strategy: Cache Page Translations

[CPU [TLB (translation cache)]] - memory interconnect - [ram [page table]]

Various ways to organize 16-entry TLB
  - Direct mapped
  - Two-way set associative
  - Four-way set associative
  - Fully associative

Lookup:
  - Calculate set (tag % num_sets)
  - Search for tag w/in resulting set

### TLB Associativity

Higher Associativity:
  - Better utilized collisions
  - slower
  - hardware intensive

Lower Associativity:
  -

### TLB Performance

Increase page size: fewer unique page translations needed to access same amount of memory

TLB Reach: # entires * Page size

### Locality

_Spatial_: future accesses to nearby addresses

_Temporal_: future access will be repeats to same data accessed in recent time

### TLB Replacement Policies

_LRU_

_Random_

### Context switches

Solutions:
  - Flush TLB
  - Record PID (ASID)

Even w/ ASID, other processes pollute TLB. Ends up discarding process A's TLB entries for B's entries

Architectures can have multiple TLBS
  - 1 TLB for data, 1 TLB for instruction
  - 1 TLB for regular pages, 1 for 'super pages'
