# Ch. 28: Locks

### 28.1: Locks - the Basic Idea

Lock is just a variable, simply holds the state of the lock at any instant in time
  - either available (unlocked or free), or acquired (locked/held)

`lock()` attempts to acquire the lock; if does, becomes 'owner' of the lock and enters the critical section

### 28.2: Pthread Locks

POSIX library uses the name *mutex* for lock, as it provides _mutual exclusion_ between threads

*Coarse-grained* locking strategy: one big lock that's used any time any critical section is accessed

*Fine-grained* approach: protect different data and data structures with different locks, and thus allowing more threads to be in locked code at once

### 28.3: Building a Lock

### 28.4: Evaluating Locks

*fairness*: Each thread gets a fair shot at acquiring the lock once it's free

Performance
  - no contention: when single thread is running and grabs and releases the lock
  - multiple threads contending

### 28.5: Controlling Interrupts

Old implementations would simply toggle interrupts

Interrupt masking is sometimes used to guarantee atomicity when accessing its own data structures

### 28.6: Test and Set (Atomic Exchange)

*Test and set instruction*: Also known as atomic exchange, follows the code pattern below

```
void init: sets lock to 0
void lock: while(mutex->flag == 1) { ; // spin-wait }
void unlock: sets lock to 0
```

*Spin-wait* in the while loop

### 28.7: Building a Working Spin Lock

```
int TestAndSet(int *old_ptr, int new) {
        int old = *old_ptr; // fetch old value at old_ptr
        *old_ptr = new;     // store ’new’ into old_ptr
        return old;         // return the old value
}
```

Acts as single, atomic operation

*Spin Lock*: simply spins, using CPU cycles, until the lock becomes available
  - requires _preemptive scheduler_ on single processor (needs to be interrupted)

Don't provide fairness guarantees.

Performance:
  - Single processor: wastes CPU cycles running threads that are trying to acquire the lock
  - Multiple CPUs: performs reasonably well. Spinning to wait for a lock held on another processor doesn't waste many cycles

### 28.9: Compare-and-Swap (compare and exchange)

```
int CompareAndSwap(int *ptr, int expected, int new) {
    int actual = *ptr;
    if (actual == expected)
        *ptr = new;
    return actual;
}
```

Performs better than test-and-set

### 28.10: Load-Linked and Store-Conditional

Similar load instruction

Difference in store-conditional, which only succeeds (and updates the value stored at the address just load-linked from) if no intervening store to the address has taken place

### 28.11: Fetch-And-Add

```
int FetchAndAdd(int *ptr) {
    int old = *ptr;
    *ptr = old + 1;
    return old;
}
```

*Ticket Lock*: uses ticket and turn variable in combination to build a lock.
  - When a thread wishes to acquire a lock, it first does an atomic fetch and add on the ticket value; that value is now considered this thread's 'turn'

Provides fairness in lock acquisition

### 28.13: A Simple Approach - Just Yield

Instead of spinning, use new OS primitive `yield()` to give up the CPU and let another thread run.

Moves caller from the _running_ state to the _ready_

Still requires context switch

Doesn't tackle starvation problem

### 28.14: Using Queues - Sleeping Instead of Spinning

`park()` puts calling thread to sleep

`unpark(threadID)` wake particular thread

*wakeup/waiting race*: thread that's just about to park switches to another thread that then releases the lock. This leads to the former sleeping forever.
  - Solaris solved this with `setpark()`, which allows thread to indicate it's about to park

### 28.15: Different OS, Different Support

Linux provides *Futex* locks, `futex_wait(address, expected)` and `futex_wait(address)`

### 28.16: Two-Phase Locks

Linux approach uses the *two-phase lock* - spins for a while, if not acquired during the first spin phase, enters second phase where caller is put to sleep, only woken up when the lock later becomes free. 
