# Ch. 26: Concurrency: An Introduction

A _multi-threaded_ program has more than one point of execution (i.e. multiple PCs)

Each thread is very much like a separate process, except that they share the same address space

Each thread has its own private set of registers

Upon context switch, thread state is saved in *thread control block (TCB)*

In a multi-threaded process, each thread has its own stack (_thread local storage_)

### 26.1: An Example: Thread Creation

Threads get created and scheduled - it's ultimately up to the scheduler as to when they're going to run and return; which makes things hard.

### 26.2: Why It Gets Worse - Shared Data

### 26.3: The Heart of the Problem - Uncontrolled Scheduling

*Race Condition*: The results depend on the timing execution of the code
  - Often gives _indeterminate_ results

*Critical section*: piece of code that accesses a shared variable (or more general, a shared resource) and must not be concurrently executed by more than one thread

*Mutual Exclusion*: property that guarantees that if one thread is executing w/in the critical section, the others will be prevented from doing so.

### 26.5: The Wish For Atomicity

*Atomically*: When the instruction executes, it would perform the update as desired. 'As a unit', 'All or none'. Sometimes, the grouping of many actions into a single atomic action is called a _transaction_.

*Synchronization Primitives*: Used to turn short sequences of instructions into atomic blocks of execution

### 26.6: One More Problem - Waiting For Another

Need to support sleeping/waking conditions - 
